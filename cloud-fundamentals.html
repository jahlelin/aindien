<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Learning Cloud Computing for Beginners - Jason&#x27;s Computing Guides</title><meta name="description" content="This is a guide for learning Cloud Computing."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://aindien.com/cloud-fundamentals.html"><link rel="alternate" type="application/atom+xml" href="https://aindien.com/feed.xml" title="Jason&#x27;s Computing Guides - RSS"><link rel="alternate" type="application/json" href="https://aindien.com/feed.json" title="Jason&#x27;s Computing Guides - JSON"><style>:root{--body-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--heading-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--logo-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--menu-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol"}</style><link rel="stylesheet" href="https://aindien.com/assets/css/style.css?v=166a31b4480c68773db8a06507216db7"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://aindien.com/cloud-fundamentals.html"},"headline":"Learning Cloud Computing for Beginners","datePublished":"2023-12-26T23:12-06:00","dateModified":"2025-08-20T20:40-05:00","description":"This is a guide for learning Cloud Computing.","author":{"@type":"Person","name":"Jason Moore","url":"https://aindien.com/authors/jason-moore/"},"publisher":{"@type":"Organization","name":"Jason Moore"}}</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-393JFJ482L"></script><script>window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-393JFJ482L');</script><script id="mcjs">!function(c,h,i,m,p){m=c.createElement(h),p=c.getElementsByTagName(h)[0],m.async=1,m.src=i,p.parentNode.insertBefore(m,p)}(document,"script","https://chimpstatic.com/mcjs-connected/js/users/5aefa50c3a5900492b165a83f/93dcd5a76da18d3becc7e677f.js");</script></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://aindien.com/">Jason&#x27;s Computing Guides</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://aindien.com/about-me.html" target="_self">Andromeda</a></li><li><a href="https://aindien.com/c/" target="_self">C++</a></li><li><a href="https://aindien.com/linux/" target="_self">Linux</a></li><li><a href="https://aindien.com/networking/" target="_self">Networking</a></li><li><a href="https://aindien.com/git/" target="_self">Git</a></li><li><a href="https://aindien.com/python/" target="_self">Python</a></li><li><a href="https://aindien.com/ai/" target="_self">AI</a></li></ul></nav><div class="search"><div class="search__overlay js-search-overlay"><div class="search__overlay-inner"><form action="https://aindien.com/search.html" class="search__form"><input class="search__input js-search-input" type="search" name="q" placeholder="search..." aria-label="search..." autofocus="autofocus"></form><button class="search__close js-search-close" aria-label="Close">Close</button></div></div><button class="search__btn js-search-btn" aria-label="Search"><svg role="presentation" focusable="false"><use xlink:href="https://aindien.com/assets/svg/svg-map.svg#search"/></svg></button></div></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://aindien.com/media/website/computing-logo-2.jpg" srcset="https://aindien.com/media/website/responsive/computing-logo-2-xs.jpg 300w, https://aindien.com/media/website/responsive/computing-logo-2-sm.jpg 480w, https://aindien.com/media/website/responsive/computing-logo-2-md.jpg 768w, https://aindien.com/media/website/responsive/computing-logo-2-lg.jpg 1024w, https://aindien.com/media/website/responsive/computing-logo-2-xl.jpg 1360w, https://aindien.com/media/website/responsive/computing-logo-2-2xl.jpg 1600w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" alt=""></figure><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2023-12-26T23:12">December 26, 2023</time></div><h1>Learning Cloud Computing for Beginners</h1><div class="post__meta post__meta--author"><a href="https://aindien.com/authors/jason-moore/" class="feed__author invert">Jason Moore</a></div></div></header></div><div class="wrapper post__entry"><p><span style="font-weight: 400;">This is a guide for learning Cloud Computing.</span></p><p> </p><p><a target="_blank" href="https://www.amazon.com/dp/B0DJ7VD2CB" rel="noopener">Check out my Cloud Computing book on Amazon.</a></p><p> </p><div class="post__toc"><h3>Table of Contents</h3><ul><li><a href="#mcetoc_1hrc5n9osj">Getting Started With Cloud Computing</a></li><li><a href="#mcetoc_1htsoercn1n">Security and Compliance in AWS</a></li><li><a href="#mcetoc_1htsomcbl34">Management Tools for AWS</a></li><li><a href="#mcetoc_1i318aq4ab">Services For Cloud Computing</a></li></ul></div><h2> </h2><h2 id="mcetoc_1hrc5n9osj" class="align-center"><span style="color: #236fa1;"><strong>Getting Started With Cloud Computing</strong></span></h2><p><span style="font-weight: 400;">Cloud terminology is everywhere these days. It means a lot of different things. Cloud</span><span style="font-weight: 400;">can be used in a generic way or a specific app. Cloud computing is the purchase of services that include various degrees of automation and support depending on the needs of the customer.</span></p><p><span style="font-weight: 400;">A cloud application is one that does not reside or run on a user’s device. It is accessed through a network. Cloud application portability is the ability to migrate a cloud application from one cloud to another.</span></p><p><span style="font-weight: 400;">Cloud computing is a network-accessible platform that delivers services from a large and scalable pool of systems. Cloud data portability is the ability to move data between cloud providers. The cloud deployment model is how cloud computing is delivered through a set of configurations and features of virtual resources.</span></p><p><span style="font-weight: 400;">The cloud deployment models are public, private, and hybrid. Data portability is the ability to move data from one system to another without having to re-enter it. </span></p><p><span style="font-weight: 400;">Infrastructure as a service is a cloud service category where infrastructure level services are provided by a cloud service provider. Measured services are delivered and billed for in a metered way.</span></p><p><span style="font-weight: 400;">Multitenancy is having multiple customers and applications running within the same environment but in a way that they are isolated from each other and not visible to each other but share the same resources.</span></p><p><span style="font-weight: 400;">On-demand self service is where a customer can provision services in an automatic manner with minimal involvement from the provider. Platform as a service is a cloud service category where platform services are provided to the cloud customer and the cloud provider is responsible for the system up to the level of the actual application. Resource pooling is the aggregation of resources allocated to cloud customers by the cloud provider.</span></p><p><span style="font-weight: 400;">Reversibility is the ability of a cloud customer to remove all data and applications from a cloud provider and completely remove all data from their environment. Software as a service is a cloud service category in which a full application is provided to the cloud customer and the cloud service provider maintains responsibility for the entire infrastructure, platform, and application. A tenant is one or more cloud customers sharing access to a pool of resources.</span></p><p class="align-left"><span style="color: #169179;"><strong>Cloud Roles</strong></span></p><p><span style="font-weight: 400;">A cloud auditor is someone that is specifically responsible for conducting audits of cloud systems and cloud applications. A cloud service broker is a partner that serves as an intermediary between a cloud service customer and cloud service provider. A cloud service customer is one that holds a business relationship for services with a cloud service provider. </span></p><p><span style="font-weight: 400;">A cloud service partner is one that holds a relationship with either a cloud service provider or a cloud service customer to assist with cloud services and their delivery. A cloud service provider is one that offers cloud services to cloud service customers. A cloud service user is one that interacts with and consumes services offered by a cloud services customer. </span></p><p class="align-left"><span style="color: #169179;"><strong>Cloud Computing Characteristics</strong></span></p><p><span style="font-weight: 400;">Cloud computing has a few attributes that are common to every system. The following are key to be considered a cloud environment.</span></p><ul><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">On-demand self service</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Broad network access</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Resource pooling</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Rapid elasticity</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Metered service</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Multitenancy</span></li></ul><p><span style="font-weight: 400;">On-demand self service is where cloud services can be put into use by the customer through an automation system. They can be requested and provisioned as needed. They should be able to do all of this without interacting with another person. Of course, you will need to have the technical skills to do these tasks. This is usually done through a web portal because that is the easiest way. </span></p><p><span style="font-weight: 400;">Broad network access is when all cloud services are accessed over a network. Services can be accessed through thick or thin clients. You can use mobile devices, laptops, or desktops. </span></p><p><span style="font-weight: 400;">Resource pooling is one of the most important concepts in cloud computing. In systems like these, you always have a mix of applications being used by different customers. Resources are dynamically allocated depending on the customer’s needs. Customers can request additional resources and pay for them as needed.</span></p><p><span style="font-weight: 400;">Some organizations have computing needs that vary through the year. They can increase or decrease their resource allocation through a few buttons. This is a great benefit and saves organizations a ton of money. </span></p><p><span style="font-weight: 400;">Rapid elasticity is when new resources can be rapidly expanded at any time. It is also usually done through a web portal. </span></p><p><span style="font-weight: 400;">Metered service is the type of service where resources are logged for billing and reporting. Services that can be included with a metered service include storage, networking, memory, and processing.</span></p><p><span style="font-weight: 400;">Multitenancy is where everything has a physical separation between customers. Providers often use separate network gear for this. There is often virtual separation too depending on the resource. </span></p><p class="align-left"><span style="color: #169179;"><strong>Virtualization</strong></span></p><p><span style="font-weight: 400;">Virtualization is a key component of cloud computing. It models a traditional data center. A data center includes a bunch of racks and servers in them. These servers and their software allow for many different customers and subsequent resource pooling. Virtualization allows providers to virtually or logically allocate resources to customers when they need it instead of physically adding a new data drive.</span></p><p><span style="font-weight: 400;">Different virtualization environments are what makes this happen. There are many companies that offer virtualization products and it is a great service. It is the underlying technology of cloud computing.   </span></p><p class="align-left"><span style="color: #169179;"><strong>Cloud Categories</strong></span></p><p><span style="font-weight: 400;">There are three main types of cloud service categories. They are:</span></p><ul><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Infrastructure as a service</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Platform as a service</span></li><li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Software as a service</span></li></ul><p><span style="font-weight: 400;">Infrastructure as a service is the base service. It allows the most control over the environment. Basically, you handle just about everything. You can customize almost everything in this model. You just have to know how to do it. You can scale this very quickly to whatever limits you can afford.</span></p><p><span style="font-weight: 400;">You do not have to own any physical hardware. You will have high availability and easily be able to meet any security requirements. Pricing is controlled by metered usage so you can use as much or as little as you want. There is usually a choice of hardware if you prefer it. </span></p><p><span style="font-weight: 400;">Platform as a service is the next model. It offers slightly less control so the customer can focus on their business instead of having to worry about hardware and other configurations. This model will auto-scale as you need it and provision resources. The platform still allows a lot of control and customization. You can choose whatever software and operating system that benefits you the most.</span></p><p><span style="font-weight: 400;">You can easily upgrade any of the software yourself. This allows a lot of cost savings for your environment. Another advantage is licensing. The cloud provider is responsible for this. This takes a massive off the customer as this can become quite the headache if you are using software that requires licenses. </span></p><p><span style="font-weight: 400;">Software as a service is the last model we will talk about. This model allows the least control but the customer can just focus on the application itself that they need access to. They do not have to worry about anything else and do not need a system administrator to manage all of the other functions as they do in PaaS and IaaS models.</span></p><p><span style="font-weight: 400;">The customer can typically do everything themselves in SaaS models. SaaS is the most popular and widely known. We use them every day. Examples are Gmail and Drive. This model is generally the cheapest way to use an application. You will only have support costs if you ask for it. Therefore, you are only paying for the licensing costs of the software. They do not need to have a system administrator or physical access to any hardware. Licensing will be the main cost and you can choose what you need. </span></p><p class="align-left"><span style="color: #169179;"><strong>Cloud Models</strong></span></p><p><span style="font-weight: 400;">There are three main types of cloud deployment models. These are public, private, and hybrid models. </span></p><p><span style="font-weight: 400;">A public cloud is one that provides services to the general public. Examples of this are AWS, Digital Ocean, and Rackspace. Anyone can pay for services and use them. Setup is very easy and inexpensive. The provider handles all of the hardware and virtualization needed to provide resources. Customers pay for only what they need and they can have as many resources as they are willing to pay for. </span></p><p><span style="font-weight: 400;">A private cloud is different in that it is usually run by an organization and restricted to its own members. It is owned and managed by this single organization. The organization has complete control over this private cloud. This includes all hardware and software.  </span></p><p><span style="font-weight: 400;">A hybrid cloud is a mix of these together. This is done sometimes to meet the needs of the organization. There can be any combination of the previous models put together. You can manage certain parts by yourself and contract other parts of the model to someone else.</span></p><p><span style="font-weight: 400;">Anything critical can be maintained locally while non-critical parts can be outsourced. This type of model is a good way to handle disaster recovery. Since you can split your operations into multiple physical areas, recovering from a hurricane, for instance, is much easier. As in the other systems, scalability is always there as the organization is in complete control of it.  </span></p><p class="align-left"><span style="color: #169179;"><strong>Universal Concepts</strong></span></p><p>There are several concepts that are common to most cloud models. These include interoperability, scalability, focus on security, your privacy, auditability, governance, maintenance, and reversability.</p><p>Interoperability is the ease with which one can move or reuse components of an application. The underlying platform, opersting system, location, API structure, or cloud provider should not be an impediment to moving services easily and efficiently to an alternative solution.An organization that has a high degree of interoperability with its systems is not bound to one cloud provider and can easily move to another if the level of service or price is not suitable.</p><p>Elasticity and scalability are similar concepts in terms of the changing of resources allocated to a system or application to meet current demands. The difference between the two concepts related to the manner in which the level of resources is altered. With scalability, the allocated resources are changed statistically to meet anticipated demands or new deployments in services. Elasticity adds the ability for the dynamic modification of resources to meet demands as they evolve.</p><p>The concepts of performance, availability, and resiliency shoudl be considered in any cloud environment due to the nature of cloud infrastructures and models. Given the size and scale of most cloud implementations, performance should always be second nature to a cloud. Resiliency and high availability are also important in a cloud environment. If any of these areas fall short, customers will not stay long with a cloud provider and will quickly move to other providers.</p><p>The easiest way to remember the difference between availability and resiliency is the extent to which a system is affected by outages. Availability pertains to the overall status if a system is up or down, whereas resiliency pertains to the ability of a system to continue to function when some aspect experiences an outage.</p><p>Portability is the key feature that allows systems to easily and seamlessly move betweenb different cloud providers. An organizsation that has its systems optimized for portability opens up enormous flexibility to move between different providers and hosting models and can be leveraged in a variety of ways. From a cost perspective, portability allows an organization to continually shop for cloud hosting services.</p><p>Whereas a contract will spell out the general terms and costs for services, the SLA, or service level agreements, is where the real meat of the business relationship and concrete requirements come into play. The SLA spells out in clear terms the minimum requirements for uptime, availability, processes, customer service and support, security controls and requirements, auditing and reporting, and potentially many other areas that will define the business relationship and the success of it. </p><p>Regulatory requirements are those imposed upon a business and its operations either by law, regulation, policy, or standards and guidelines. These requirements are specific to the locality in which the company or application is based or specific to the nature of the data and transactions conducted. These requirements can carry financial, legal, or even crminal penalties for failure to comply. Sanctions and penalties can apply to the company itself or even in some cases the individuals working for the company and on its behalf, depending on the locality and the nature of the violation. </p><p>Security is always a paramount concern for any system or application. Within a cloud environment, there can be a lot of management with using a newer technology, and many will be uncomfortable with the idea of having corporate and sensitive data not under direct control of internal IT staff and hardware housed in proprietary data centers. Depending on company policy, different applications and systems will have their own specific security requirements and controls. Within a cloud environment, this becomes of particular interest because many customers are tenants within the same framwork and the cloud provider needs to ensure each customer that their controls are being met, and done so in a way that the cloud provider can support, with varying requirements.</p><p>Privacy in the cloud environment requires particular care due to the large number of regulatory and legal requirements that can differ greatly by use and location. Adding even more complexity is the fact that laws and regulations may differ based on where the data is stored and where the data is exposed and consumed.</p><p>Cloud providers will very often have in place mechanisms to keep systems housed in geographic locations based on a customer's requirements and regulations, but it is incumbent on the cloud security professional to verify and ensure that these mechanisms are functioning properly.</p><p>Most leading cloud providers supply their customers with a good deal of auditing, including reports and evidence that show user activity, compliance with controls and regulations, systems and processes that runs, and an explanation of what they all do, as well as information, data access, ande modification records. Auditability of a cloud environment is an area where the cloud security professional needs to pay particular attention because the customer does not have full control over the environment like they would in a proprietary and traditional data center model.</p><p>Governance at its core involves assigning jobs, tasks, roles, and responsibilities and ensuring they are satisfactorily performed. Whether in a traditional data center or a cloud model, governance is mostly the same and undertaken by the same approach, with a bit of added complexity in a cloud environment due to data protection requirements and the role of the cloud provider. Although the cloud environment adds complexity to governance and oversight, it also brings some benefits as well.</p><p>With the different types of cloud services, it is important for the contract and SLA to clearly spell out maintenance responsibilities for all upgrades, patching, and maintenance, whereas with PaaS and certainly IaaS, some duties belong to the cloud customer while the rest are retained by the cloud provider. Outlining maintenance and testing practices and timelines with the SLA is particularly important for applications that may not always work correctly because of new versions or changes to the underlying system.</p><p>Reversability is the ability of a cloud customer to take all their systems and data out of a cloud provider and have assurances from the cloud provider that all of the data has been securely and completely removed within an aggred-upon timeline. In most cases, this will be done by the cloud customer by first retrieving all of their data and processes from the cloud provider, serving notice that all active and available files and systems should be deleted, and then removing all traces from long-term storage archives or storage at an agreed-upon point in time.</p><h2 id="mcetoc_1htsoercn1n" class="align-center"><span style="color: #236fa1;"><strong>Security and Compliance in AWS</strong></span></h2><p><span style="font-weight: 400;">Security is a primary focus for AWS across all services and one of the most prominent benefits of using a cloud provider. AWS can implement extremely robust security through economies of scale that can far exceed what any organization could have the finances and experience to implement on their own.</span></p><p><span style="color: #169179;"><strong>Shared Responsibility Model</strong></span></p><p><span style="font-weight: 400;">Any large and complex IT system is built upon multiple layers of services and components, and a cloud is certainly a prime example of that model. With any cloud offering, the underlying infrastructure is the sole responsibility of the cloud provider. This includes everything from the physical building and facilities to the power infrastructure and redundancy, physical security, and network cabling and hardware components. This also includes the underlying computing infrastructure such as hypervisors, CPU, memory, and storage.</span></p><p><span style="font-weight: 400;">Make sure to understand the shared responsibilities model and what the customer is responsible for in each service category.</span></p><p><span style="font-weight: 400;">With Infrastructure as a Service, the customer is responsible for everything beginning with the operating system. The cloud provider is responsible for the underlying host infrastructure from which the customer can deploy virtual services into, whether they are virtual machines or virtual networking components.</span></p><p><span style="font-weight: 400;">With Platform as a Service, the cloud provider is responsible for an entire hosting platform, including all software, libraries, and middleware that the customer needs. The customer then deploys their application code and data into the environment. This is most heavily used for DevOps, where developers can quickly obtain fully featured hosting environments and only need to deploy their code and any needed data to test and develop with, and do not need to worry about any underlying operating system or middleware issues.</span></p><p><span style="font-weight: 400;">With Software as a Service, the cloud provider is responsible for everything except specific customer or user data. SaaS is a fully featured application that a customer only needs to load users or do minimal configuration, along with possibly importing data about customers or services.</span></p><p><span style="color: #169179;"><strong>Managed vs. Unmanaged</strong></span></p><p><span style="font-weight: 400;">A major question for any customer is whether to use managed or unmanaged resources within a cloud environment. While both can provide what is needed to meet the business needs of the customer, there are pros and cons of each approach.</span></p><p><span style="font-weight: 400;">Managed resources are those where the cloud provider is responsible for the installation, patching, maintenance, and security of a resource. On the inverse, unmanaged resources are those hosted within a cloud environment, but where the customer bears responsibility for host functions. Managed resources will typically cost more than unmanaged resources. </span></p><p><span style="color: #169179;"><strong>Regulatory Compliance</strong></span></p><p><span style="font-weight: 400;">If your application utilizes or stores any type of sensitive information, there will be specific regulatory requirements that you will need to incur compliance with. This type of data can range from credit card and financial information to health records, academic records, or government systems and data.</span></p><p><span style="font-weight: 400;">To assist with meeting regulatory requirements, AWS offers their Artifact service, which can be accessed directly from the AWS management console. As part of the Artifact service, AWS undergoes certification reviews and audits by various governing bodies. An additional feature that AWS offers through Artifact is enabling a customer to review and accept agreements for their individual account and what they need to maintain compliance with, along with terminating the agreement if no longer needed. </span></p><p><span style="color: #169179;"><strong>Data Security</strong></span></p><p><span style="font-weight: 400;">Several toolsets and technologies are commonly used as data security strategies. These are: encryption, key management, masking, obfuscation, anonymization, and tokenization.</span></p><p><span style="font-weight: 400;">With the concepts of multitenancy and resource pooling being central to any cloud environment, the use of encryption to protect data is essential and required, as the typical protections of physical separation and segregation found in a traditional data center model are not available or applicable to a cloud environment. The architecture of an encryption system has three basic components: the data itself, the encryption engine that handles all the encryption activities, and the encryption keys used in the actual encryption and use of the data.</span></p><p><span style="font-weight: 400;">Data in transit is the state of data when it is actually being used by an application and is traversing systems or going between the client and the actual application. Whether the data is being transmitted between systems within the cloud or going out to a user’s client, data in transit is when data is most vulnerable to exposure of unauthorized capture. Within a cloud hosting model, the transmission between systems is even more important than with a traditional data center due to multitenancy; the other systems within the same cloud are potential security risks and vulnerable points where data capture could happen successfully. </span></p><p><span style="font-weight: 400;">In order to maintain portability and interoperability, the cloud security professional should make the processes for the encryption of data in transit vendor neutral in regard to the capabilities or limitations of a specific cloud provider. The most common method for data in transit encryption is to use the well known SSL and TLS technologies under HTTPS. With many modern applications utilizing web services as the framework for communications, this has become the prevailing method, which is the same method used by clients and browsers to communicate with servers over the internet. </span></p><p><span style="color: #169179;"><strong>Data at Rest</strong></span></p><p><span style="font-weight: 400;">Data at rest refers to information stored on a system or device. This data can be stored in many different forms to fit within this category.</span></p><p><span style="font-weight: 400;">Data residing on a system is potentially exposed and vulnerable far longer than short transmission and transaction operations would be, so special care is needed to ensure its protection from unauthorized access. </span></p><p><span style="font-weight: 400;">While encrypting data is central to the confidentiality of any system, the availability and performance of data are equally as important.It is important to ensure that encryption methods provide high levels of security and protection and do so in a manner that facilitates high performance and system speed.</span></p><p><span style="font-weight: 400;">With portability and vendor lock-in considerations, it is important to ensure that encryption systems do not effectively cause a system to be bound to a proprietary cloud offering. Data at rest encryption and security are very important in a cloud environment due to the reliance on virtual machines. In a traditional data center, you can have systems that are powered off and inaccessible. In a virtual environment, when a system is not powered on or started, the disk and memory are gone, but the underlying image still exists within storage and carries a possibility of compromise or corruption, especially if a developer has stored application or customer data on the VM image. </span></p><p><span style="color: #169179;"><strong>Encryption with Data States</strong></span></p><p><span style="font-weight: 400;">Encryption is used in various manners and through different technology approaches, depending on the state of the data at the time.With data in use, the data is being actively accessed and processed. Because this process is the most removed from and independent of the host system, technologies such as data rights management and information rights management are the most capable and mature approaches that can be taken at this time.</span></p><p><span style="color: #169179;"><strong>Challenges With Encryption</strong></span></p><p><span style="font-weight: 400;">There are a myriad of challenges with implementing encryption. Some are applicable no matter where the data is housed, and others are specific to cloud environments. A central challenge to encryption implementations is the dependence on key sets to handle the actual encryption and decryption processes. Without the proper security of encryption keys, the entire encryption scheme could be rendered vulnerable and insecure. With any software based encryption scheme, core computing components such as processor and memory are vital, and within a cloud environment specifically, these components are shared across all of the hosted customers.</span></p><p><span style="color: #169179;"><strong>Encryption Implementations</strong></span></p><p><span style="font-weight: 400;">The actual implementation of encryption and how it is applied will depend largely on the type of storage being used within the cloud environment. With database storage systems, two layers of encryption are typically applied and available. First, database systems will reside on volume storage systems, resembling a typical file system of a server model. The actual database files can be protected through encryption methods at the file system level. This also serves to protect the data at rest.</span></p><p><span style="font-weight: 400;">For object storage, apart from the encryption at the actual file level, which is handled by the cloud provider, encryption can be used within the application itself. The most prevalent means for this is through IRM technologies or via encryption within the application itself. With IRM, encryption can be applied to the objects to control their usage after they have left the system. With application-level encryption, the application effectively acts as a proxy between the user and the object storage and ensures encryption during the transaction. However, once the object has left the application framework, no protection is provided. </span></p><p><span style="font-weight: 400;">Lastly, with volume storage, many of the typical encryption systems used on a traditional server model can be employed within a cloud framework. This encryption is most useful with data at rest scenarios. Due to the application itself being able to read the encrypted data on the volume, any compromise of the application will render the file system encryption ineffective when it comes to protecting the data.</span></p><p><span style="color: #169179;"><strong>Hashing</strong></span></p><p><span style="font-weight: 400;">Hashing involves taking data of arbitrary type, length, or size and using a function to map a value that is of a fixed size. Hashing can be applied to virtually any type of data object, including text strings, documents, images, binary data, and even virtual machine images. </span></p><p><span style="font-weight: 400;">The main value of hashing is to quickly verify the integrity of data objects. Within a cloud environment this can offer great value with virtual machine images and the potentially large number of data locations within a dispersed environment. As many copies of a file are potentially stored in many different locations, hashing can be used to very quickly verify that the files are of identical composure and that the integrity of them has not been compromised.  </span></p><p><span style="font-weight: 400;">A large variety of hashing functions are commonly used and supported. The vast majority of users will have no problem using any of the freely and widely available options, which will suit their needs for data integrity and comparison without issue. </span></p><p><span style="color: #169179;"><strong>Key Management</strong></span></p><p><span style="font-weight: 400;">Key management is the safeguarding of encryption keys and the access to them.  Within a cloud environment, key management is an essential and highly important task, while also being very complex. One of the most important security considerations with key management is the access to the keys and the storage of them. Access to keys in any environment is extremely important and critical to security. In a cloud environment, where you have multitenancy and the cloud provider personnel having broad administration access to systems, there are more considerations than in a traditional data center concerning the segregation and control of the staff of the customer. </span></p><p><span style="font-weight: 400;">No matter what hosting model is used by an organization, a few principles of key management are important. Key management should always be performed only on trusted systems and by trusted processes, whether in a traditional data center or in a cloud environment. In a cloud environment, careful consideration must be given to the level of trust that can be established within the environment of the cloud provider and whether that will meet management and regulatory requirements. If the externally hosted key management system becomes unavailable, like an inadvertent firewall change or ACL change, the entire system will be inaccessible.</span></p><p><span style="font-weight: 400;">Key storage can be implemented in a cloud environment within the same virtual machine as the encryption service or engine. Internal storage is the simplest implementation, it keeps the entire process together.</span></p><p><span style="color: #169179;"><strong>Tokenization</strong></span></p><p><span style="font-weight: 400;">Tokenization is the practice of utilizing a random and opaque token value in data to replace what otherwise would be a sensitive or protected data object. The token value is usually generated by the application with a means to map it back to the actual real value, and then the token value is placed in the data set with the same formatting and requirements of the actual real value, so that the application can continue to function without different modifications or code changes. Tokenization represents a way for an organization to remove sensitive data from an application without having to introduce more intensive processes such as encryption to meet regulatory or policy requirements. </span></p><p><span style="color: #169179;"><strong>Data Loss Prevention</strong></span></p><p><span style="font-weight: 400;">A major concept and approach employed in a cloud environment to protect data is known as data loss prevention. It is a set of controls and practices put in place to ensure that data is only accessible and exposed to those users and systems authorized to have it. The goals of this strategy for an organization are to manage and minimize risk, maintain compliance with regulatory requirements, and show due diligence on the part of the application and data owner. </span></p><p><span style="color: #169179;"><strong>DLP Components</strong></span></p><p><span style="font-weight: 400;">Any DLP implementation is composed of three common components: discovery and classification, monitoring, and enforcement. The discovery and classification stage is the first stage of the DLP implementation. It is focused on the actual finding of data that is pertinent to the DLP strategy, ensuring that all instances of it are known and able to be exposed to the DLP solution, and determining the security classification and requirements of the data once it has been found. This also allows the matching of data within the environment to any regulatory requirements for its protection and assurance. </span></p><p><span style="font-weight: 400;">Once data has been discovered and classified, it can then be monitored with DLP implementations. The monitoring stage encompasses the core function and purpose of a DLP strategy. </span></p><p><span style="font-weight: 400;">The final stage of a DLP implementation is the actual enforcement of policies and any potential violations caught as part of the monitoring stage. If any potential violations are detected by the DLP implementation, a variety of measures can be automatically taken, depending on the policies set forth by the management.</span></p><p><span style="color: #169179;"><strong>DLP Data States</strong></span></p><p><span style="font-weight: 400;">With data at rest, the DLP solution is installed on the systems holding the data, which can be servers, laptops, desktops, workstations, or mobile devices. In many instances, this will involve archived data and long-term storage data.</span></p><p><span style="font-weight: 400;">With data in transit, the DLP solution is deployed near the network perimeter to capture traffic as it leaves the network through various protocols such as http,https, and smtp. It looks for data that is leaving or attempting to leave the area that does not conform to security policies. </span></p><p><span style="font-weight: 400;"> Lastly, with data in use, the DLP solution is deployed on the workstations or devices in order to monitor the data access and use from the endpoints. The biggest challenges with this type of implementation are reach and the complexity of having all access points covered. </span></p><p><span style="font-weight: 400;">DLP on end-user devices can be a particular challenge for any cloud application. Because it requires the end user to install an application or plug in to work, you will need to make sure you fully understand the types of devices your users will be utilizing, as well as any costs and requirements associated with the use of the technology.</span></p><p><span style="color: #169179;"><strong>DLP Cloud Implementations and Practices</strong></span></p><p><span style="font-weight: 400;">The cloud environment brings additional challenges to DLP. The biggest difference is the way cloud environments store data. Data in a cloud is spread across large storage systems, with varying degrees of replication and redundancy, and oftentimes where the data will be stored and accessed is unpredictable. For a DLP strategy, this can pose a particular challenge because it makes properly discovering and monitoring all data used by a system or application more difficult, especially because the data can change locations over time.</span></p><p><span style="color: #169179;"><strong>Data De-identification</strong></span></p><p><span style="font-weight: 400;">Data de-identification involves using masking, obfuscation, or anonymization. The theory behind masking or obfuscation is to replace, hide, or remove sensitive data from data sets. The most common use for masking is making available test datasets for nonproduction and development environments.  By replacing sensitive data fields with random or substituted data, these nonproduction environments can quickly utilize datasets that are similar to production for testing and development, without exposing sensitive information to systems with fewer security controls and less oversight.</span></p><p><span style="font-weight: 400;">Typically masking is accomplished either by entirely replacing the value with a new one or by adding characters to a data field. This can be done wholesale on the entire field or just portions of it.</span></p><p><span style="font-weight: 400;">The two primary methods for masking are static masking and dynamic masking. With static masking, a separate and distinct copy of the data set is created with masking in place. This is typically done through a script or other process that will take  a standard data set, process it to mask the appropriate and predefined fields, and then output the dataset as a new one with the completed masking done. The static method is most appropriate for data sets that are created for nonproduction environments. With dynamic masking, production environments are protected by the masking process being implemented between the application and data layers of the application. This allows for a masking translation to take place live in the system and during normal application processing of data. Dynamic masking is usually done where a system needs to have full and unmasked data but certain users should not have the same level of access.  </span></p><p><span style="font-weight: 400;">With data anonymization, data is manipulated in a way to prevent the identification of an individual through various data objects. It is often used in conjunction with other identifiers such as masking. Data generally has direct and indirect identifiers, with direct identifiers being the actual personal and private data, and indirect identifiers being attributes such as demographic and location data. Data anonymization is the process of removing the indirect identifiers to prevent such asn identification from taking place. </span></p><p><span style="color: #169179;"><strong>AWS Identity and Access Management</strong></span></p><p><span style="font-weight: 400;">Just like a root account on a computer system, the AWS root account has full access to everything under your account. It can create users, provision resources, and incur financial obligations for any activities that are done with it. As with superuser accounts on any computer system, it is a best practice to not use the root account unless absolutely necessary, but instead to provision accounts that have more limited access. </span></p><p><span style="font-weight: 400;">The AWS IAM dashboard can be found at </span><a href="https://console.aws.amazon.com/iam"><span style="font-weight: 400;">https://console.aws.amazon.com/iam</span></a><span style="font-weight: 400;"> and you can log into this address using the same email address and password for your root account.</span></p><p><span style="color: #169179;"><strong>Securing The Root User</strong></span></p><p><span style="font-weight: 400;">When you created your root account, you established a password for it. This password is what you will use to access the AWS console when using the root account. Along with a strong password, MFA will add another layer of security to the account so it is recommended to do this. </span></p><p><span style="color: #169179;"><strong>IAM User Groups and Roles</strong></span></p><p><span style="font-weight: 400;">Groups are used to assign a standard set of permissions to users as they are added to the system. As you add more users, going through each user and assigning permissions can become a very labor intensive process. It is easy to make errors like this. Groups represent the way to create packages of settings that are maintained in a single location. As users are added to the system, they can be added to the appropriate groups and will automatically inherit the appropriate permissions in a consistent manner.</span></p><p><span style="font-weight: 400;">Roles in AWS are the granular permissions that users can be granted. Within each AWS service, there are multiple roles that allow different activities, such as reading data, creating data, deploying services, and provisioning access. The AWs system has predefined roles for every single service offering that you can select to attach to groups. Within each service offering, there are several different roles that grant different types of access.</span></p><p><span style="color: #169179;"><strong>Federated Access</strong></span></p><p><span style="font-weight: 400;">A powerful way for provisioning user access to AWS is through federated access. With federated access, you can use technologies such as SAML or Microsoft Active Directory to provision users, rather than creating them manually through the  IAM account process in the console. The big advantage with using federated access is that users will use accounts and credentials they already have established to access AWS. This enables an organization to use already existing security and account practices, without having to worry about maintaining them in another system. </span></p><p><span style="color: #169179;"><strong>SAML</strong></span></p><p><span style="font-weight: 400;">SAML 2.0 is the latest standard put out by the nonprofit OASIS consortium and their security services technical committee and can be found at </span><a href="https://www.oasis-open.org/standards#samlv2.0"><span style="font-weight: 400;">https://www.oasis-open.org/standards#samlv2.0</span></a><span style="font-weight: 400;">. SAML is xml based and it is used to exchange information used in the authentication and authorization process between different parties. Specifically, it is used for information exchange between identity providers and service providers, and it contains within the xml block the required information that each system needs or provides. </span></p><p><span style="color: #169179;"><strong>User Reporting</strong></span></p><p><span style="font-weight: 400;">As with any system that has a number of users on it, you will want a way to keep track of what users you have, what access they have, when they last logged in, and their status of being issued keys and when they were last rotated. This report is offered as a csv download that you can either review directly from the csv or import into any data or reporting tool you desire. The report can be accessed from the left menu with the credential report button.</span></p><p><span style="color: #169179;"><strong>AWS Support</strong></span></p><p><span style="font-weight: 400;">When we created an account, we selected the free support option. It is not ideal for organizations that are more heavily invested in AWS and certainly not for anyone running production business services in AWS. </span></p><h2 id="mcetoc_1htsomcbl34" class="align-center"><span style="color: #236fa1;"><strong>Management Tools for AWS</strong></span></h2><p><span style="font-weight: 400;">The AWS management console is the main resource where you can control all of your services and perform any operations. To access the console, go to https://console.aws.amazon.com and log in with your credentials. The console has many menus that point to their many services. On any screen, in the upper right corner of the console is a dropdown menu to change regions that you are viewing. For some services that are global in nature, you will not see regions displayed within the dashboard for that service. </span></p><p> </p><p><span style="font-weight: 400;">As you are learning about the AWS core services, keep track of which ones are global in nature and not bound to regions. Many services are offered at a global level, and no selection or configuration in regard to regions or availability zones is necessary.</span></p><p> </p><p><span style="color: #169179;"><strong>AWS CLI</strong></span></p><p><span style="font-weight: 400;">The AWS command line interface provides a way to manage AWS services and perform many administrative functions without having to use the web based management console. Through the use of the command line interface, users can also script and automate many functions through whatever programming language they are familiar with or desire to use for automation. Each AWS service has command line interface commands that are pertinent to it and can be found in the AWS documentation. </span></p><p> </p><p><span style="color: #169179;"><strong>Developer Tools</strong></span></p><p><span style="font-weight: 400;">AWS CodeBuild is a fully featured code building service that will compile and test code as well as build deployment packages that are ready for implementation. Codebuild is a fully managed service that will automatically scale to the needs of developers, alleviating their need to manage and scale a system. </span></p><p> </p><p><span style="font-weight: 400;">AWS CodeCommit is a managed service for secure Git repositories. With the popularity of Git for code versioning, the AWS service allows users to be up and running quickly and in a secure environment, without having to configure and manage their own repository systems. It will automatically scale to the needs of users and is completely compatible with any tools and software that have Git capabilities.</span></p><p> </p><p><span style="font-weight: 400;">AWS CodeDeploy is a managed deployment service that can deploy code fully across AWS services or on-premises servers. The service is designed to handle complex deployments and ensure that all pieces and configurations are properly deployed, allowing a savings in time spent on verification after rollouts. It will fully scale to any resources that are needed.</span></p><p> </p><p><span style="color: #169179;"><strong>Configuration Management</strong></span></p><p><span style="font-weight: 400;">The AWS systems manager allows you to consolidate data from AWS services and automate tasks across all of your services. It allows for a holistic view of all of your services, while also allowing you to create logical groups of resources that can then be viewed in a consolidated manner. Within the Systems Manager there are many components that allow you to perform different administrative tasks. </span></p><p> </p><p><span style="font-weight: 400;">OpsCenter provides a consolidated view for developers and operations staff to view and investigate any operational issues. Data from many different resources are all centralized. It allows for a quick view of your entire environment and helps diagnose problems as quickly as possible. </span></p><p> </p><p><span style="font-weight: 400;">Explorer is a customizable dashboard that provides information on the health of your entire AWS environment and can consolidate data spanning multiple accounts and regions. </span></p><p> </p><p><span style="font-weight: 400;">AWS AppConfig provides an API and console method for applying configuration changes across AWS services from a centralized service. This is done in much the same way code is deployed out to multiple locations. AppConfig can quickly deploy configuration changes to different instances of compute services and ensure they are applied in a uniform and consistent manner.</span></p><p> </p><p><span style="font-weight: 400;">Resource Groups allow for logical grouping of resources within AWS for how they are presented within Systems Manager. This allows a user to group services by application, department, tier, or any other manner they find useful, rather than looking at all resources collectively.</span></p><p> </p><p><span style="font-weight: 400;">Keep in mind the concept of resource groups, especially with large deployments within AWS. The use of resource groups can help segment services to specific applications and groups and assist with monitoring your services within AWS.</span></p><p> </p><p><span style="color: #169179;"><strong>Global Infrastructure</strong></span></p><p><span style="font-weight: 400;">AWs runs a very large cloud infrastructure that is distributed throughout the world. This network is divided into different segments that are geographically based, such as region and availability zones. AWS also runs a network of Edge services throughout the world that serve a portion of AWS services and are optimized for low-latency and responsiveness to requests.</span></p><p> </p><p><span style="font-weight: 400;">AWS organizes resources throughout the world in regions. Each region is a group of logical data centers called Availability Zones. While each region may seem like it is a data center or physical location, it is actually a collection of independent data centers that are grouped and clustered together, providing redundancy and fault tolerance.</span></p><p> </p><p><span style="font-weight: 400;">When you provision resources within AWS, they can exist in only one region and are hosted on the physical hardware present at it. That does not mean you cannot replicate instances and virtual machines across multiple regions and around the world, but each individual instance only exists in one region. </span></p><p> </p><p><span style="color: #169179;"><strong>Core AWS Services</strong></span></p><p><span style="font-weight: 400;">AWS offers a large number of core services that are widely used and well known throughout the world. It offers robust monitoring and auditing tools that span the breadth of all AWS service offerings. Monitoring systems are designed to collect and consolidate event data and auditing information from any services allocated under your account and provide them to you from a uniform and centralized dashboard. </span></p><p> </p><p><span style="font-weight: 400;">CloudWatch is the AWS service for monitoring and measuring services running within the AWS environment. It provides data and insights on application performance and how it may change over time, resource utilization, and a centralized and consolidated view of the overall health of systems and services. It is very useful to developers, engineers, and managers. Within any IT system, large amounts of data are produced in the form of system and application logs, but also data on performance and metrics. </span></p><p> </p><p><span style="font-weight: 400;">Across large systems, this can result in a large amount of data that is coming from many different sources. This can pose considerable challenges ranging from anyone looking to synthesize the data and formulate a picture of system health and performance, down to developers looking for specific events or instances within applications.</span></p><p> </p><p><span style="font-weight: 400;">It collects and consolidates all of this data into a single service, making it much easier and more efficient to access. With this consolidation, developers and managers can see a picture of their overall systems and how they are performing, versus looking at individual systems or components of systems separately. </span></p><p> </p><p><span style="font-weight: 400;">CloudTrail is the AWs service for performing auditing and compliance within your AWS account. It pairs with CloudWatch to analyze all of the logs and data collected from the services within your account, which can then be audited and monitored for all activities done by users and admins within your account. This enables a full compliance capability and will store an historical record of all account activities. Should any investigations become necessary, all of the data is preserved and easily searchable. </span></p><p> </p><p><span style="font-weight: 400;">CloudTrail will log all account activities performed, regardless of the method through which they are done. It logs all activity through the management console, command line interface, and any API calls that are made, along with the originating IP address and all time and date data. If unauthorized changes are made, or if a change causes a disruption in services or system problems, the logs and reports available can enable an admin to quickly determine what was done and by whom.</span></p><p> </p><p><span style="color: #169179;"><strong>AWS Shield</strong></span></p><p><span style="font-weight: 400;">This provides protection from and mitigation of DDOS attacks on AWS services. It is always active and monitoring services, providing continual coverage without needing to engage AWS support for assistance should an attack occur. It comes in two different service categories, Standard and Advanced. Standard coverage is provided at no additional charge and is designed to protect against common DDOS attacks, especially for any accounts utilizing CloudFront or Route 53. This will protect websites and applications from the most frequently occurring attacks and virtually all known attacks on layer 3 and 4 against CloudFront and Route 53.</span></p><p> </p><p><span style="color: #169179;"><strong>AWS WAF</strong></span></p><p><span style="font-weight: 400;">AWS WAF is a web application firewall that protects web applications against many common attacks. It comes with an array of preconfigured rules from AWS that will offer comprehensive protection based on common top security risks, but you also have the ability to create your own rules. The WAF includes an API that can be used to automate rule creation and deployment of them to your allocated resources. Also included is a real time service view into your web traffic that you can then use to automatically create new rules and alerts. It is included at no additional cost for anyone who has purchased the AWS Shield Advanced tier. If you are not utilizing the Advanced Shield tier, you can use AWS WAF separately and will incur costs based on the number of rules you create and the number of requests they service. Remember the difference between Shield and WAF. Shield operates at the layer 3 and 4 network levels and is used to prevent DDOS attacks, versus WAF that operates at the Layer 7 level and can take action based on the specific contents of web traffic and requests. </span></p><h2 id="mcetoc_1i318aq4ab" class="align-center"><span style="color: #236fa1;"><strong>Services For Cloud Computing</strong></span></h2><p>AWS runs a very large cloud infrastructure that is distributed throughout the<br>world. This network is divided into different segments that are geographically<br>based. AWS also runs a network of Edge services throughout the worls that serve<br>a portion of AWS services and are optimized for low-latency and responsiveness<br>to requests.<br>   <br>When you provision resources within AWS, they can exist in only one region and<br>are hosted on the physical hardware present at it. That does not mean you cannot<br>replicate instances and virtual machines across multiple regions and around the<br>world, but each individual instance only exists in one region.<br>  <br><span style="color: #169179;"><strong>AWS Services</strong></span><br>When you provision a resource, the decision of which region to locate it in can<br>depend on a few different factors such as: customer locations, security<br>requirements, and regulatory requirements. It makes sense to host your<br>applications and resources closer to your customers. This will yield the fastest<br>network times and responsiveness. It may also make sense, depending on your<br>application's needs and your apetite for risk, to completely separate resources<br>or instances. Lastly, many jurisdictions have regulatory requirements that<br>dictate how personal and financial data can be used and transported. In many<br>instances they are required to stay within geographic areas or within their own<br>borders.<br><br>The use of regions for regulatory compliance is very important. Most regulations<br>are built upon where the data resides or is being processed, and the ability<br>within AWS to control, with most services, where that happens makes compliance<br>much easier.<br>  <br>To keep order and make it easier to know what service you are using, as well as<br>the region hosting it, all AWS services use endpoints that are formulaic in<br>nature. This enables anyone with knowledge of the AWS topography to quickly know<br>where and what a service is just by seeing the endpoint.<br>  <br><span style="color: #169179;"><strong>Availability Zones</strong></span><br>While regions represent a group or cluster of physical data centers, an AWS<br>Availability Zone represents those actual physical locations. Each AWS data<br>center is built with fully independent and redundant power, coooling,<br>netowrking, and physical computing hardware. All network connections are<br>dedicated lines, supporting the highjest possible throughput and lowest levels<br>of latency.<br>  <br>As each region is made up of multiple Availability Zones, there are direct<br>connections for networking access between them, and all traffic is encrypted.<br>This allows resources within a region to be spread out and clustered between the<br>Availability Zones, without worrying about latency or security.<br><br>When provision resources within AWS, you will select the region from one of the<br>options given. The list will contain all of those that are available within that<br>region.<br>  <br>To provide optimal responsiveness for customers, AWS maintains a network of Edge<br>locations throughout the world to provide low latency access to data. These<br>locations are geographically dispersed throughout the world to be close to<br>customers and organizations in order to provide the fastest response times.<br>Unlike regular AWS regions and Availability Zones, Edge locations are optimized<br>to perform a narrow set of tasks and duties, allowing them to be optimally tuned<br>and maintained for their intended focus.<br>  <br>Edge locations run a minimal set of services to optimize delivery speeds. These<br>include Amazon CloudFront, Amazon Route 53, AWS Shield, AWS WAF, and Lambda<br>Edge. CloudFront is a content delivery network that allows cached copies of data<br>and content to be distributed on Edge servers closest to customers. Route 53 is<br>a DNS service that provides very fast and robust lookup services. Shield is a<br>DDoS protection service that constantly monitors and reacts to any attacks. WAF<br>is a web application firewall that monitors and protects against web exploits<br>and attacks based on rules that inspect traffic and requests. Lambda Edge<br>provides a runtime environment for application code to be run on a CDN without<br>having to provision systems or manage them.<br><br><span style="color: #169179;"><strong>Core Services</strong></span><br>AWS offers a alrge number of core services that are widely used and well known<br>throughout the IT world.<br>  <br>CloudWatch is the AWS service for monitoring and measuring services running<br>within the AWS environment. It provides data and insights on application<br>performance and how it may change over time, resource utilization, and a<br>centralised view of the overall health of systems and services. It is very<br>useful to developers, engineers, and managers.<br>  <br>CloudTrail is the AWS service for performing auditing and compliance within your<br>AWS account. It pairs with CloudWatch to analyze all the logs and data collected<br>from the services within your account, which can then be audited and monitored<br>for all activities done by users and admins within your account. This enables a<br>full compliance capability and will store an historical record of all account<br>activities. Should any investigations become necessary, all of the data is<br>preserved and easily searchable.<br>  <br>Shield provides protection from and mitigation of DDoS attacks on AWS service.<br>It is always active and monitoring AWS services, providing continual coverage<br>without needing to engage AWS support for assistance should an attack occur. AWS<br>Shield comes in two different service categories, Standard and Advanced.<br><br>AWS WAF is a web application firewall that protects web applications against<br>many common attacks. It comes with an array of preconfigured rules from AWS that<br>will offer comphrehensive protection based on common top security risks, but you<br>also have the ability to create your own rules. The AWS WAF includes an API that<br>can be used to automate rule creation and deployment of them to your allocated<br>resources. Also included is a real time view into your web traffic that you can<br>then use to automatically create new rules and alerts.<br> <br>Remember the difference between Shield and WAF. Shield operates at the layer 3<br>and 4 network levels and is used to prevent DDoS attacks, versus WAF that<br>operates at the layer 7 content level and can take action based on the specific<br>contents of web traffic and requests.<br> <br><span style="color: #169179;"><strong>Networking and Content Delivery</strong></span><br>AWS offers robust networking and content delivery systems that are designed to<br>optimize low latency and responsiveness to any queries, as well as complete<br>fault tolerance and high availability.<br> <br>With Amazon Virtual Private Cloud, you can create a logically defined space<br>within AWS to create an isolated virtual network. Within this network, you<br>retain full control over how the network is defined and allocated. You fully<br>control the I{ space, subnets, routing tables, and network gateway settings<br>within your VPC, and you have full use of both IPv4 and IPv6.<br><br>Security Groups in AWS are virtual firewalls that are used to control inbound<br>and outbound traffic. Security groups are applied on the actual instance within<br>a VPC versus at the subnet level. This means that in a VPC where you have many<br>services or virtual machines deployed, each one can have different security<br>groups applied to them. In fact,each instance can have up to 5 security groups<br>applied to it, allowing different policies to be enforced and maintain<br>granularity and flexibility for administrators and developers.<br> <br><span style="color: #169179;"><strong>ACL's</strong></span><br>Access control lists are security layers on the VPC that control traffic at the<br>subnet level. This differs from security groups that are on each specific<br>instance. However, many times both will be used for additional layers of<br>security.<br> <br><span style="color: #169179;"><strong>Subnets</strong></span><br>Within a VPC, you must define a block of IP addresses that are available to it.<br>These are called a Classless Inter-Domain Routing block. By default, a VPC will<br>be created with a CIDR of 172.31.0.0/16. This default block will encompass all<br>IP addresses from 172.31.0.0 to 172.31.255.255. While the default subnet<br>configuration for AWS uses IPv4 addressing, IPv6 is also available if desired or<br>required.<br><br><span style="color: #169179;"><strong>Elastic Load Balancing</strong></span><br>Elastic Load Balancing is used to distribute traffic across the AWS<br>infrastructure. This can be done on varying degrees of granularity, ranging from<br>spanning across multiple Availability Zones or within a single Availability<br>Zone. It is focused on fault tolerance by implementing high availability,<br>security, and auto-scaling capabilities. There are three different types of load<br>balancing under its umbrella: application load balancer, network load balancer,<br>and classic load balancer.<br> <br>Layer 7 of the OSI model pertains to the actual web traffic and content.<br>Developers can take advantage of data such as the HTTP method, URL, parameters,<br>headers, and so on, in order to tune load balancing based on the specifics of<br>their applications and the type of traffic and user queries it receives.<br> <br><span style="color: #169179;"><strong>Route 53</strong></span><br>Amazon Route 53 is a robust, scalable, and highly available DNS service. Rather<br>than running their own DNS services or being dependent on another commercial<br>service, an organization can utilize Route 53 to transform names into their IP<br>addresses, as well as having full IPv6 compatibility and access. Route 53 can be<br>used for services that reside inside AWS, as well as those of AWS.<br><br><span style="color: #169179;"><strong>CloudFront</strong></span><br>Amazon CloudFront is a CDN that allows for delivery of data and media to users<br>with the lowest levels of latency and the highest levels of transfer speeds.<br>This is done by having CloudFront systems distributed across the entire AWS<br>global infrastructure and fully integrated with many AWS services, such as S3,<br>EC2, and Elastic Load Balancing. CloudFront optimizes speed and delivery by<br>directing user queries to the closest location to their requests. This is<br>especially valuable and useful for high resource demand media such as live and<br>streaming video.<br> <br><span style="color: #169179;"><strong>Storage</strong></span><br>AWS offers extremely fast and expandable storage to meet the needs of any<br>applications or system. These offerings range from block storage used by EC2<br>instances to the widely used object storage of S3. AWS offers different tiers of<br>storage to meet specific needs of production data processing systems versus<br>those used for archiving and long term storage.<br> <br><span style="color: #169179;"><strong>Elastic Block Store</strong></span><br>Amazon Elastic Block Storage is a high performance storage that is used in<br>conjunction with EC2 where high throughput data operations are required. This<br>will typically include file systems, media services, and databases. There are<br>four types of EBS volumes that a user can pick from to mee their specific needs.<br>Two of the volume types feature storage backed by solid-state drives and two use<br>traditional hard disk drives.</p><p class="align-left"><span style="color: #169179;"><strong>S3</strong></span><br>Amazon Simple Storage Service is the most prominent and widely used storage<br>service under AWS. It offers object storage at incredibly high availability<br>levels, with stringent security and backups, and is used for everything from<br>websites, backups, and archives to big data implementations.<br> <br>Remember that bucket names must be globally unique within AWS, and each bucket<br>can only exist within one region.<br><br><span style="color: #169179;"><strong>S3 Storage Classes</strong></span><br>S3 offers four storage classes for users to pick from, depending on their needs.<br>Storage classes are set at the object level, and a bucket for a user may contain<br>objects using any of the storage classes concurrently.<br> <br>S3 Standard is used for commonly accessed data and is optimized for high<br>throughput and low latency service. Used widely for cloud applications,<br>websites, content distribution, and data analytics. Encryption is supported for<br>data both at rest and in transit and is resilient to the loss of an entire<br>Availability Zone.<br><br><span style="color: #169179;"><strong>S3 Intelligent Tiering</strong></span><br>Best used for data where usage patterns are unknown or may change over time.<br>This class works by spanning objects across two tiers: one that is optimized for<br>frequent access and the other for lesser access. For a small fee, AWS will<br>automatically move an object between the two tiers based on access.<br> <br><span style="color: #169179;"><strong>S3 Standard Infrequent Access</strong></span><br>Ideally used where access will be infrequent for an object, but where access is<br>requested, a quick response is necessary. This is often used for backups and<br>disaster recovery files that are not accessed with any regularity, but when<br>needed there is an immediacy requirement.<br> <br><span style="color: #169179;"><strong>S3 One Zone Infrequent Access</strong></span><br>Ideal for data that is infrequently used, requires quick access when it is<br>accessed, but does not require the robust fault tolerance and replication of<br>other S3 classes. Rather than being spread across the typical three Availability<br>Zones, objects under this storage class are housed on a single Availability<br>Zone. This realizes cost savings for users, as it is cheaper than other S3<br>storage classes that span multiple Availability Zones.<br><br><span style="color: #169179;"><strong>S3 Permissions</strong></span><br>AWS S3 offers three different layers of permissions and security controls on S3<br>objects: bucket, user, and object access control lists. With bucket<br>policies, security policies are applied at the user level of the bucket. These<br>policies can apply to all objects within the bucket or just some objects. For<br>example, for a private bucket that you desire to only allow internal access to<br>objects, a bucket-level policy can be applied that automatically protects every<br>object within. However, if you have a mix of objects in your bucket, you may<br>have some that are protected to specific users for access, while others, such as<br>those used for public web pages, are open and available to the entire internet.<br>As policies are applied to objects, the ability to read, write, and delete<br>objects can all be controlled separately.<br> <br><span style="color: #169179;"><strong>S3 Encryption</strong></span><br>When you upload any objects to S3, the data within the object is static and<br>written to storage within the AWS infrastructure. If you upload an object that<br>contains personal or sensitive data, that will now reside in AWS and be<br>accessible based upon the policies and security controls that you have applied<br>to it. While the bucket and user policies you have in place will be applied to<br>those objects, it is possible to upload data that should be protected and<br>somehow slips through your policies for various reasons.<br><br><span style="color: #169179;"><strong>S3 Versioning</strong></span><br>By default, when you update an object in S3, it is overwritten and replaces what<br>you previously had uploaded. In many cases this is fine, but it puts the<br>responsibility on the user to ensure they have a backup copy of the object or to<br>otherwise preserve the copy. Without doing so, once they have uploaded a new<br>copy, whatever existed before is gone.<br> <br><span style="color: #169179;"><strong>S3 Object Life Cycle</strong></span><br>To help manage versioning in AWS S3, the service provides automation tools,<br>called actions, to handle how versions are stored and when they are removed from<br>the system. This will be particularly useful as the number of objects you have<br>increases or with objects that are regularly updated and will begin to accrue a<br>large number of versions.<br> <br><span style="color: #169179;"><strong>S3 Glacier and S3 Glacier Deep</strong></span><br>S3 Glacier is a special type of S3 storage that is intended to be a secure<br>solution for long term data archiving and backups. As compared to regular S3<br>storage options, Glacier is offered at significant cost savings. These savings<br>are much greater when compared to the costs of on-premises storage solutions for<br>long term archiving. Depending on retrieval needs, S3 Glacier Deep is a subset<br>of Glacier that is intended for the longest term storage with the least likely<br>needs for retrieval.<br><br><span style="color: #169179;"><strong>AWS Storage Gateway</strong></span><br>the AWS Storage Gateway provides storage for hybrid cloud services that gives<br>access to your on-premises resources to the full array of storage services in<br>AWS. This enables a customer to extend their storage capabilities into AWS<br>seamlessly and with very low latency. A common usage for Storage Gateway is for<br>customer to use AWS to store backups of images from their on-premises<br>environment, or to use the AWS cloud storage to backup their file shares. Many<br>customers also utilize Storage Gateway as a key component to their disaster<br>recovery strategy and planning.<br> <br><span style="color: #169179;"><strong>AWS Backup</strong></span><br>AWS Backup provides backup services for all AWS services. It provides a single<br>resource to configure backup policies and monitor their usage and success across<br>any services that you have allocated. This allows administrators to access a<br>single location for all backup services without having to separately configure<br>and monitor on a per-service basis across AWS. From the AWS Backup console,<br>users can fully automate backups and perform operations such as encryption and<br>auditing. AWS backup has been certified as compliant with many regulatory<br>requirements.<br><br><span style="color: #169179;"><strong>AWS Snow</strong></span><br>AWS Snow is designed for offering compute and storage capabilities to those<br>organizations or places that are outside the areas where AWS regions and<br>resources operate. Snow is based on hardware devices that contain substantial<br>compute and storage resources that can be used both as devices for data<br>processing away from the cloud and as a means to get data into and out of AWS.<br>This is particularly useful in situations where high speed or reliable<br>networking is now possible.<br> <br><span style="color: #169179;"><strong>Compute Services</strong></span><br>With any system or application, you need an underlying compute infrastructure to<br>actually run your code, content, or services. AWS offers the ability through EC2<br>to run full virtual instances that you maintain control over and can customize<br>as much as you like, as well as managed environments that allow you to just<br>upload your content or code and be quickly running, without having to worry<br>about the underlying environment. These include EC2, Lightsail, Elastic<br>Beanstalk, Lambda, and Containers.<br> <br><span style="color: #169179;"><strong>EC2</strong></span><br>Amazon Elastic Compute cloud is the main offering for virtual servers in the<br>cloud. It allows users to create and deploy compute instances that they will<br>retain full control over and offers a variety of configuration options for<br>resources.<br><br>Amazon Machine Images are the basis of virtual compute instances in AWs. An<br>image is basically a data object that is a bootable virtual machine and can be<br>deployedd throughout the AWs infrastructure. AMI's can be either those offered<br>by AWS through their Quick Start options, those offered by vendors through the<br>AWS marketplace, or those created by users for their own specific needs.<br> <br>Remember that costs for Marketplace applications will be presented as two costs.<br>The licensing costs from the vendor for use of the image, as well as the EC2<br>costs for hosting it and the compute/storage resources it will consume.<br><br>EC2 instance types are where the underlying hardware resources are married with<br>the type of image you are using. The instance type will dictate the type of CPU<br>image used, how many virtual CPU's it has, how much memory, the type of storage<br>used, network bandwidth, and the underlying EBS bandwidth.<br> <br>It is not necessary to memorize all of the instance types and which purposes<br>they associate with.<br> <br><span style="color: #169179;"><strong>Lightsail</strong></span><br>Lightsail is the quickest way to get into AWS for new users. It offers<br>blueprints that will configure fully ready systems and application stacks for<br>you to immediately begin using and deploying your code or data into. Lightsail<br>is fully managed by AWS and is designed to be a one click deployment model to<br>get you up and running quickly at a low cost.</p><p><span style="color: #169179;"><strong>Elastic Beanstalk</strong></span><br>Elastic beanstalk is designed to be even easier and quicker to get your<br>applications up and running in that Lightsail is. With Elastic beanstalk, you<br>choose the application platform that your code is written in. Once you provision<br>the instance you can deploy your code into it and begin running. You only select<br>the platform you need, you do not select specific hardware or compute resources.<br> <br><span style="color: #169179;"><strong>Lambda</strong></span><br>AWS Lambda is a service for running code for virtually any application or back<br>end service. all you need to do is upload your code, and there are no systems or<br>resources to manage. The code can be called by services or applications, and you<br>will only incur costs based on the processing time and the number of times your<br>code is called, as well as the memory that you allocate. You will always have<br>the level of resources you need available to run your code without having to<br>provision or monitor anything.<br> <br><span style="color: #169179;"><strong>Containers</strong></span><br>With typical server models, there is an enormous duplication of resources when<br>replicas of systems are created. When you launch several instances of EC2, each<br>one has its own operating system and underlying functions and services that are<br>needed to run. before your application code is even used, each instance is<br>consuming a certain amount of compute resources just to exist. A modern approach<br>to this problem has been through the use of containers, such as Docker. This<br>allows a single system instance to host multiple virtual environments within it<br>while leveraging the underlying infrastructure.<br><br><span style="color: #169179;"><strong>Databases</strong></span><br>As many modern applications are heavily dependent on databases, AWS has several<br>database service offerings that will fit any type of use needed, ranging from<br>relational databases to data warehousing. AWs provides robust tools for<br>migrating databases from legacy and on-premises systems into AWS, as well as<br>transitioning between different database services.<br> <br><span style="color: #169179;"><strong>Database Models</strong></span><br>Databases follow two general methods. They can be either relational or<br>non-relational. which one younuse is entirely dependent on the needs of your<br>application and the type of data it is accessing and dependent on.<br> <br>Relational databases are often referred to as structured data. A relational<br>database utilizes a primary key to track a unique record, but then can have many<br>data elements associated with it.<br> <br>Non-relational databases are referred to as unstructured data. While their<br>tables also utilize a primary key, the data paired with that primary key is not<br>restircted to the type of data. This allows applications to store a variety of<br>data within their tables. However, it also restricts queries against these<br>tables to the primary key value, as the paired data could be in different<br>formats and structures and would not be efficient or stable to query from<br>applications generally.<br><br>Make sure you understand the differences between relational and non-relational<br>databases and what they are used for, especially the key aspects of how they may<br>be searched.<br> <br><span style="color: #169179;"><strong>AWS Database Migration Service</strong></span><br>The AWS Database Migration Service is a tool for migrating data into AWS<br>databases from existing databases with minimal downtime or other interruptions.<br>The DMS can move data from most of the popular and widely used databases into<br>various AWs database services while the source system remains fully operational.<br>DMS can do migrations where the source and destination databases are the same,<br>such as moving from Microsoft SQL server from another location into a Microsoft<br>SQL server database in AWs, but it can also perform migrations where they<br>differ.<br> <br>The availability of DMS is a great opportunity for any users that have been<br>contemplating changing back-end databases but have been cautious about the level<br>of effort involved in the actual migration of data.</p><p><span style="color: #169179;"><strong> Amazon Relational Database Service</strong></span><br> Amazon RDS is an umbrella sercice that incorporates several different kinds of<br> database systems. Each system is fully managed by AWS and is optimized within<br> the AWS infrastructure for memory, performance, and I/O. All aspects of database<br> management, such as provisioning, configuration, maintenance, performance<br> monitoring, and backups, are handled by AWS, which allows the user to fully<br> focus on their applications and data.<br><br><span style="color: #169179;"><strong>Amazon Aurora</strong></span><br> Aurora is a subset of Amazon RDS that is compatible with both Microsoft SQL and<br> PostgreSQL databaes. It combines the features and simplicity of opensource<br> databases with the robust management and security of AWS services. Aurora<br> leverages the AWS infrastructure to offer highly optimized and fast database<br> services, along with the robust security and reliably of AWS.<br> <br><span style="color: #169179;"><strong> DynamoDB</strong></span><br> DynamoSB is the AWS key-value and document database solution for those<br> applications that do not need a SQL or relational database but do need extremely<br> high performance and scalable access to their data. As with other AWS services,<br> DynamoDB is fully configured, maintained, and secured by AWS, so all the user<br> needs to do is create a table and populate their data.</p><p><span style="color: #169179;"><strong>Amazon Redshift</strong></span></p><p>Redshift is a cloud based data warehouse solution offered by AWS. Unlike traditional on-premises data warehouses,Redshift leverages AWS storage to any capacity that is needed by a company, either now or into the future. Organizations will only incur costs for the storage they actually use, as well as the compute power they need to do analysis and retrieve data. Typically, an organization must spend money on having sufficient capacity and continually add both compute and storage infrastructure to support growth and expansion, resulting in expenses for idle systems. </p><p><span style="color: #169179;"><strong>Automation</strong></span></p><p>In AWS, automation is essential to enable systems to be rapidly and corretly deployed and configured. Amazon CloudFormation implements an automated way to model infrastructure and resources within AWS via either a text file or through the use of programming languages. This allows administration to build out templates for the provisioning of resources that can then be repeated in a secure and reliable manner. As you build new systems or replicate services, you can be assured that they are being done in a consistent and uniform manner, negating the process of building out from a base image and then having to apply different packages, configurations, or scripts to fully build up systems to a ready state. With the use of file-based templates, CloudFormation allows infrastructure and services to be treated as code. This allows adminstrators to use version control to track changes to the infrastructure and use build pipelines to deploy the infrastructure changes. CloudFormation not only helps with infrastructure, it can also help build and deploy your applications. </p><p><span style="color: #169179;"><strong>End-User Computing</strong></span></p><p>AWS offers powerful tools to organizations to provide end-user computing such as virtual desktops and access to applications or internally protected websites. </p><p><span style="color: #169179;"><strong>WorkSpaces</strong></span></p><p>Amazon WorkSpaces is a Desktop as a Service implementation that is built, maintained, configured, and secured through AWS as a managed service. WorkSpace offers both Windows and Linux desktop solution that can be quickly deployed anywhere throughout the AWS global infrastructure. As many organizations have moved to virtual desktop infrastructure solutions, WorkSpaces enables them to offer the same solutions to their users without the need to actually purchase and maintain the hardware required for the VDI infrastructure, as well as the costs of managing and securing it.</p><p><span style="color: #169179;"><strong>AppStream</strong></span></p><p>AppStream is a sercice for providing managed and streaming applications via AWS. By streaming applications, the need to download and install applications is removed, as they will be run through a browser. This eliminates the need for an organization to distribute software and support the installation and configuration of it to their users. This can be particularly useful to organizations like acedemic institutions that can offer a suite of software to their students without the need for them to actually obtain and install it.</p><p><span style="color: #169179;"><strong>WorkLink</strong></span></p><p>WorkLink offers users the ability to access internal applications through the use of mobile devices. Traditionally this access would be controlled and secured through the use of technologies like virtual private networks or through the use of mobile device manament utilities. Both of these technologies must be already installed and configured on a user's device before they can be used. </p><p> </p><p><br><br></p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on August 20, 2025</p><ul class="post__tag"><li><a href="https://aindien.com/cloud-computing/">Cloud Computing</a></li></ul><div class="post__share"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Faindien.com%2Fcloud-fundamentals.html" class="js-share facebook" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://aindien.com/assets/svg/svg-map.svg#facebook"/></svg> <span>Facebook</span> </a><a href="https://twitter.com/share?url=https%3A%2F%2Faindien.com%2Fcloud-fundamentals.html&amp;via=_Aindien&amp;text=Learning%20Cloud%20Computing%20for%20Beginners" class="js-share twitter" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://aindien.com/assets/svg/svg-map.svg#twitter"/></svg> <span>Twitter</span></a></div><div class="post__bio bio"><div class="bio__info"><h3 class="bio__name"><a href="https://aindien.com/authors/jason-moore/" class="invert" rel="author">Jason Moore</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://aindien.com/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://aindien.com/python-basics.html" class="invert post__nav-link" rel="prev"><span>Previous</span> Learning Python for Beginners</a></div><div class="post__nav-next"><a href="https://aindien.com/windows-essentials.html" class="invert post__nav-link" rel="next"><span>Next</span> Configuring and Troubleshooting Windows  </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://aindien.com/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav><div class="post__related related"><div class="wrapper"><h2 class="h5 related__title">You should also read:</h2><article class="related__item"><div class="feed__meta"><time datetime="2022-10-13T17:44" class="feed__date">October 13, 2022</time></div><h3 class="h1"><a href="https://aindien.com/economics-essentials.html" class="invert">Learning Economics for Beginners</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2022-08-29T23:40" class="feed__date">August 29, 2022</time></div><h3 class="h1"><a href="https://aindien.com/r-essentials.html" class="invert">Learning R for Data Science</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2021-07-05T22:23" class="feed__date">July 5, 2021</time></div><h3 class="h1"><a href="https://aindien.com/linux-essentials-.html" class="invert">Learning Linux for Beginners</a></h3></article></div></div><div class="banner banner--after-post"><div class="wrapper"><link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css"><style type="text/css">#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */</style><div id="mc_embed_signup"><form action="https://aindien.us11.list-manage.com/subscribe/post?u=5aefa50c3a5900492b165a83f&amp;id=1c348b805a" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate><div id="mc_embed_signup_scroll"><h2>Subscribe</h2><div class="indicates-required"><span class="asterisk">*</span> indicates required</div><div class="mc-field-group"><label for="mce-EMAIL">Email Address <span class="asterisk">*</span></label> <input type="email" name="EMAIL" class="required email" id="mce-EMAIL"></div><div class="mc-field-group"><label for="mce-FNAME">First Name</label> <input type="text" name="FNAME" id="mce-FNAME"></div><div class="mc-field-group"><label for="mce-LNAME">Last Name</label> <input type="text" name="LNAME" id="mce-LNAME"></div><div id="mce-responses" class="clear"><div class="response" id="mce-error-response" style="display:none"></div><div class="response" id="mce-success-response" style="display:none"></div></div><div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_5aefa50c3a5900492b165a83f_1c348b805a" tabindex="-1"></div><div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div></div></form></div><script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script></div></div></main><footer class="footer"><div class="footer__copyright"><p>Jason Moore 2022</p></div><button class="footer__bttop js-footer__bttop" aria-label="Back to top"><svg><title>Back to top</title><use xlink:href="https://aindien.com/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = {    
        mobileMenuMode: 'sidebar',
        animationSpeed: 300,
        submenuWidth: 'auto',
        doubleClickTime: 500,
        mobileMenuExpandableSubmenus: true, 
        relatedContainerForOverlayMenuSelector: '.top',
   };</script><script defer="defer" src="https://aindien.com/assets/js/scripts.min.js?v=f4c4d35432d0e17d212f2fae4e0f8247"></script><script>var images = document.querySelectorAll('img[loading]');

        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>